{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bert-model-header",
   "metadata": {},
   "source": [
    "# BERT Model: Fine-tuned Transformer for Fake News Classification\n",
    "\n",
    "This notebook implements a fine-tuned BERT model for binary classification of fake vs real news articles.\n",
    "\n",
    "## ðŸ”§ Steps:\n",
    "1. Import libraries and load data\n",
    "2. Minimal preprocessing (preserve structure for BERT)\n",
    "3. BERT tokenization and encoding\n",
    "4. Model setup and fine-tuning\n",
    "5. Training with validation\n",
    "6. Evaluation and comparison\n",
    "\n",
    "## âœ… Purpose:\n",
    "Achieve state-of-the-art performance using transformer architecture (~85-90% accuracy expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) for M4 acceleration\n",
      "PyTorch version: 2.7.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, auc, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_eval import save_model_results, save_trained_model\n",
    "\n",
    "\n",
    "# Import our preprocessing functions\n",
    "from preprocess import load_and_parse_data, create_train_validation_split\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for M4\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal Performance Shaders) for M4 acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU (this will be slower)\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## 2. Load and Parse Data\n",
    "\n",
    "Using our preprocessing module to load the tab-separated data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/training_data_lowercase.csv...\n",
      "Loaded 34151 articles\n",
      "Loading test data...\n",
      "Loading data from data/testing_data_lowercase_nolabels.csv...\n",
      "Loaded 9983 articles\n",
      "Training data shape: (34151, 2)\n",
      "Test data shape: (9983, 2)\n",
      "Label distribution: Counter({0: 17571, 1: 16580})\n",
      "\n",
      "Sample training data:\n",
      "Label 0: drunk bragging trump staffer started russian collusion investigation...\n",
      "Label 0: sheriff david clarke becomes an internet joke for threatening to poke people â€šin...\n",
      "Label 0: trump is so obsessed he even has obamaâ€šs name coded into his website (images)...\n"
     ]
    }
   ],
   "source": [
    "# Load data using our preprocessing function\n",
    "print(\"Loading training data...\")\n",
    "train_data = load_and_parse_data('data/training_data_lowercase.csv')\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data = load_and_parse_data('data/testing_data_lowercase_nolabels.csv')\n",
    "\n",
    "# Convert to DataFrames for easier handling\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Label distribution: {Counter(train_df['label'])}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample training data:\")\n",
    "for i in range(3):\n",
    "    print(f\"Label {train_df.iloc[i]['label']}: {train_df.iloc[i]['text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-section",
   "metadata": {},
   "source": [
    "## 3. Minimal Text Preprocessing\n",
    "\n",
    "BERT works best with minimal preprocessing - we'll only clean essential formatting issues while preserving punctuation and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length statistics (words):\n",
      "Mean: 11.7\n",
      "Median: 11.0\n",
      "95th percentile: 19.0\n",
      "99th percentile: 24.0\n",
      "\n",
      "Using max_length: 39\n"
     ]
    }
   ],
   "source": [
    "def minimal_bert_cleaning(text):\n",
    "    \"\"\"Minimal cleaning for BERT - preserve original structure\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and remove excessive whitespace only\n",
    "    text = str(text).strip()\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply minimal cleaning\n",
    "train_df['clean_text'] = train_df['text'].apply(minimal_bert_cleaning)\n",
    "test_df['clean_text'] = test_df['text'].apply(minimal_bert_cleaning)\n",
    "\n",
    "# Remove any empty texts\n",
    "train_df = train_df[train_df['clean_text'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# Analyze text lengths for optimal max_length\n",
    "text_lengths = train_df['clean_text'].str.split().str.len()\n",
    "print(f\"Text length statistics (words):\")\n",
    "print(f\"Mean: {text_lengths.mean():.1f}\")\n",
    "print(f\"Median: {text_lengths.median():.1f}\")\n",
    "print(f\"95th percentile: {text_lengths.quantile(0.95):.1f}\")\n",
    "print(f\"99th percentile: {text_lengths.quantile(0.99):.1f}\")\n",
    "\n",
    "# Choose max_length based on 95th percentile + buffer\n",
    "max_length = min(256, int(text_lengths.quantile(0.95)) + 20)\n",
    "print(f\"\\nUsing max_length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenization-section",
   "metadata": {},
   "source": [
    "## 4. BERT Tokenization and Dataset Creation\n",
    "\n",
    "Setting up BERT tokenizer and creating PyTorch datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tokenization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: bert-base-uncased\n",
      "Tokenizer vocabulary size: 30522\n",
      "Train set: 27320 samples\n",
      "Validation set: 6831 samples\n",
      "Train label distribution: Counter({0: 14056, 1: 13264})\n",
      "Validation label distribution: Counter({0: 3515, 1: 3316})\n",
      "\n",
      "Dataset sizes:\n",
      "Training: 27320\n",
      "Validation: 6831\n",
      "\n",
      "Sample tokenization shape:\n",
      "Input IDs: torch.Size([39])\n",
      "Attention mask: torch.Size([39])\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"Tokenizer vocabulary size: {len(tokenizer.vocab)}\")\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"Custom dataset for news classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create train/validation split using our preprocessing function\n",
    "train_texts, val_texts, train_labels, val_labels = create_train_validation_split(\n",
    "    [{'text': text, 'label': label} for text, label in zip(train_df['clean_text'], train_df['label'])],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Training: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "\n",
    "# Test tokenization on a sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample tokenization shape:\")\n",
    "print(f\"Input IDs: {sample['input_ids'].shape}\")\n",
    "print(f\"Attention mask: {sample['attention_mask'].shape}\")\n",
    "print(f\"Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-setup-section",
   "metadata": {},
   "source": [
    "## 5. Model Setup and Training Configuration\n",
    "\n",
    "Loading pre-trained BERT and setting up training parameters for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "model-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 109,483,778 parameters\n",
      "Model device: mps:0\n",
      "\n",
      "Training setup complete!\n",
      "Batch size: 16\n",
      "Number of epochs: 3\n",
      "Learning rate: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded with {model.num_parameters():,} parameters\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert_results',\n",
    "    num_train_epochs=3,              # Start with 3 epochs\n",
    "    per_device_train_batch_size=16,  # Adjust based on memory\n",
    "    per_device_eval_batch_size=32,   # Larger batch for evaluation\n",
    "    warmup_steps=500,                # Warmup for learning rate\n",
    "    weight_decay=0.01,               # Regularization\n",
    "    logging_dir='./bert_logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,                  # Evaluate every 500 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=None,                  # Disable wandb/tensorboard\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define metrics computation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining setup complete!\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Fine-tuning BERT on our fake news dataset with validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BERT fine-tuning...\n",
      "Training on 27320 samples\n",
      "Validating on 6831 samples\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5124' max='5124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5124/5124 13:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.089282</td>\n",
       "      <td>0.975260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>0.975992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.082121</td>\n",
       "      <td>0.980530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.072748</td>\n",
       "      <td>0.983604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.056567</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.067749</td>\n",
       "      <td>0.984190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.079204</td>\n",
       "      <td>0.985507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.073471</td>\n",
       "      <td>0.987118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.065443</td>\n",
       "      <td>0.987557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>0.987410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Training time: 13.25 minutes\n",
      "Final training loss: 0.0640\n",
      "\n",
      "Model saved to './bert_fine_tuned'\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting BERT fine-tuning...\")\n",
    "print(f\"Training on {len(train_dataset)} samples\")\n",
    "print(f\"Validating on {len(val_dataset)} samples\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model('./bert_fine_tuned')\n",
    "print(\"\\nModel saved to './bert_fine_tuned'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Comprehensive evaluation with accuracy, classification report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Model Results:\n",
      "Validation Accuracy: 0.9876 (98.76%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Fake (0)       0.99      0.98      0.99      3515\n",
      "    Real (1)       0.98      0.99      0.99      3316\n",
      "\n",
      "    accuracy                           0.99      6831\n",
      "   macro avg       0.99      0.99      0.99      6831\n",
      "weighted avg       0.99      0.99      0.99      6831\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Performance by Class:\n",
      "Fake (0): 0.9841 (98.41%)\n",
      "Real (1): 0.9913 (99.13%)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(val_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = val_labels\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nBERT Model Results:\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "class_names = ['Fake (0)', 'Real (1)']\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('BERT Model - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Performance by class\n",
    "print(\"\\nðŸ“ˆ Performance by Class:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = np.array(y_true) == i\n",
    "    class_accuracy = accuracy_score(np.array(y_true)[class_mask], y_pred[class_mask])\n",
    "    print(f\"{class_name}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "train_predictions = trainer.predict(train_dataset)\n",
    "train_y_pred = np.argmax(train_predictions.predictions, axis=1)\n",
    "train_accuracy = accuracy_score(train_labels, train_y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-results-section",
   "metadata": {},
   "source": [
    "## 8. Save Model Results\n",
    "\n",
    "Save the model evaluation results using the model_eval module for consistency with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save-model-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/full_bert_model_results.json\n",
      "Model: Full BERT Fine-tuned\n",
      "Accuracy: 0.9876 (98.76%)\n",
      "Training Time: 13.25 minutes\n",
      "Model results saved successfully!\n",
      "Model: Full BERT Fine-tuned\n",
      "Training Accuracy: 0.9991\n",
      "Validation Accuracy: 0.9876\n",
      "Training Time: 13.25 minutes\n",
      "Model Parameters: 109,483,778\n",
      "Device Used: mps\n"
     ]
    }
   ],
   "source": [
    "# Calculate additional metrics for save_model_results\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred).tolist()\n",
    "class_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Save results using the model_eval module (similar to other models)\n",
    "save_model_results(\n",
    "    model_name=\"full_bert_model\",\n",
    "    display_name=\"Full BERT Fine-tuned\",\n",
    "    accuracy=accuracy,\n",
    "    training_time_minutes=training_time/60,  # Already calculated in your training section\n",
    "    model_architecture=f\"BERT-base-uncased fine-tuned ({model.num_parameters():,} parameters)\",\n",
    "    preprocessing_type=\"minimal_cleaning\",\n",
    "    train_accuracy=train_accuracy,\n",
    "    test_accuracy=accuracy,  # Using validation accuracy as test accuracy\n",
    "    hyperparameters={\n",
    "        \"bert_model\": model_name,  # \"bert-base-uncased\"\n",
    "        \"max_length\": max_length,\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "        \"warmup_steps\": training_args.warmup_steps,\n",
    "        \"early_stopping_patience\": 2\n",
    "    },\n",
    "    dataset_info={\n",
    "        \"training_samples\": len(train_dataset),\n",
    "        \"validation_samples\": len(val_dataset),\n",
    "        \"max_sequence_length\": max_length,\n",
    "        \"total_parameters\": model.num_parameters(),\n",
    "        \"vocab_size\": len(tokenizer.vocab),\n",
    "        \"device\": str(device)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Model results saved successfully!\")\n",
    "print(f\"Model: Full BERT Fine-tuned\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Model Parameters: {model.num_parameters():,}\")\n",
    "print(f\"Device Used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-predictions-section",
   "metadata": {},
   "source": [
    "## Test Set Predictions\n",
    "\n",
    "Generate predictions for the test set and save to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "test-predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test set predictions...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9983 test samples...\n",
      "Logits shape: (9983, 2)\n",
      "Predictions shape: (9983,)\n",
      "Probabilities shape: (9983, 2)\n",
      "âœ… Saved 9983 predictions to prediction/full_bert_predictions.csv\n",
      "\n",
      "Prediction Summary:\n",
      "   Predicted Fake (0): 5034 articles\n",
      "   Predicted Real (1): 4949 articles\n",
      "   Fake prediction rate: 50.43%\n",
      "   Real prediction rate: 49.57%\n",
      "\n",
      "Confidence Statistics:\n",
      "   Mean confidence: 0.9977\n",
      "   Median confidence: 1.0000\n",
      "   Min confidence: 0.5312\n",
      "   Max confidence: 1.0000\n",
      "\n",
      "ðŸ“‹ First 5 predictions (text truncated for display):\n",
      "predicted_label | title_preview\n",
      "--------------------------------------------------\n",
      "             0 | wow! chicago protester caught on camera admits vio...\n",
      "             1 | germany's fdp look to fill schaeuble's big shoes\n",
      "             0 | mi school sends welcome back packet warning kids a...\n",
      "             1 | u.n. seeks 'massive' aid boost amid rohingya 'emer...\n",
      "             0 | did oprah just leave â€šnastyâ€š hillary wishing she w...\n",
      "\n",
      "âœ… Test set predictions completed successfully!\n",
      "   Output file: prediction/full_bert_predictions.csv\n",
      "   Format: predicted_label, title (no headers)\n"
     ]
    }
   ],
   "source": [
    "## Test Set Predictions\n",
    "# Generate predictions for the test set and save to CSV with specified format:\n",
    "# Column 1: predicted_label\n",
    "# Column 2: title (text content) \n",
    "\n",
    "print(\"Generating test set predictions...\")\n",
    "\n",
    "# Create test dataset\n",
    "test_texts = test_df['clean_text'].tolist()\n",
    "test_labels = [0] * len(test_texts)  # Dummy labels for dataset creation\n",
    "test_dataset = NewsDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "\n",
    "# Generate predictions using the trained model\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_logits = test_predictions.predictions\n",
    "test_pred_labels = np.argmax(test_logits, axis=1)\n",
    "\n",
    "# Convert logits to probabilities using softmax (for confidence statistics only)\n",
    "from scipy.special import softmax\n",
    "test_pred_probs = softmax(test_logits, axis=1)\n",
    "\n",
    "print(f\"Processing {len(test_texts)} test samples...\")\n",
    "print(f\"Logits shape: {test_logits.shape}\")\n",
    "print(f\"Predictions shape: {test_pred_labels.shape}\")\n",
    "print(f\"Probabilities shape: {test_pred_probs.shape}\")\n",
    "\n",
    "# Create submission file with specified column order:\n",
    "# predicted_label, title (no headers)\n",
    "output_file = 'prediction/full_bert_predictions.csv'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    # Write each prediction with proper CSV formatting\n",
    "    for i in range(len(test_texts)):\n",
    "        # Get prediction\n",
    "        pred_label = test_pred_labels[i]\n",
    "        \n",
    "        # Handle text formatting for CSV (escape quotes and commas)\n",
    "        title_text = str(test_texts[i])\n",
    "        # Escape quotes by doubling them\n",
    "        title_text = title_text.replace('\"', '\"\"')\n",
    "        # Wrap in quotes if contains comma, quote, or newline\n",
    "        if ',' in title_text or '\"' in title_text or '\\n' in title_text:\n",
    "            title_text = f'\"{title_text}\"'\n",
    "        \n",
    "        # Write row: predicted_label, title\n",
    "        f.write(f'{pred_label},{title_text}\\n')\n",
    "\n",
    "print(f\"âœ… Saved {len(test_pred_labels)} predictions to {output_file}\")\n",
    "\n",
    "# Display prediction summary\n",
    "print(f\"\\nPrediction Summary:\")\n",
    "print(f\"   Predicted Fake (0): {np.sum(test_pred_labels == 0)} articles\")\n",
    "print(f\"   Predicted Real (1): {np.sum(test_pred_labels == 1)} articles\")\n",
    "print(f\"   Fake prediction rate: {np.sum(test_pred_labels == 0) / len(test_pred_labels) * 100:.2f}%\")\n",
    "print(f\"   Real prediction rate: {np.sum(test_pred_labels == 1) / len(test_pred_labels) * 100:.2f}%\")\n",
    "\n",
    "# Display confidence statistics\n",
    "confidence_scores = np.max(test_pred_probs, axis=1)\n",
    "print(f\"\\nConfidence Statistics:\")\n",
    "print(f\"   Mean confidence: {confidence_scores.mean():.4f}\")\n",
    "print(f\"   Median confidence: {np.median(confidence_scores):.4f}\")\n",
    "print(f\"   Min confidence: {confidence_scores.min():.4f}\")\n",
    "print(f\"   Max confidence: {confidence_scores.max():.4f}\")\n",
    "\n",
    "# Display first few rows for verification (with truncated text for readability)\n",
    "print(f\"\\nðŸ“‹ First 5 predictions (text truncated for display):\")\n",
    "print(\"predicted_label | title_preview\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(5, len(test_pred_labels))):\n",
    "    title_preview = str(test_texts[i])[:50].replace('\\n', ' ')\n",
    "    if len(str(test_texts[i])) > 50:\n",
    "        title_preview += \"...\"\n",
    "    print(f\"{test_pred_labels[i]:>14} | {title_preview}\")\n",
    "\n",
    "print(f\"\\nâœ… Test set predictions completed successfully!\")\n",
    "print(f\"   Output file: {output_file}\")\n",
    "print(f\"   Format: predicted_label, title (no headers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae4cee",
   "metadata": {},
   "source": [
    "## Save model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90ab6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved: trained_models/full_bert_20250530_144730.joblib\n",
      "Trained model saved successfully!\n",
      "Note: For new predictions, BERT features must be extracted first using the same process.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained classifier (Note: BERT embeddings would need to be re-extracted for new data)\\n\n",
    "save_trained_model(model, model_name=\"full_bert\")\n",
    "\n",
    "print(\"Trained model saved successfully!\")\n",
    "print(\"Note: For new predictions, BERT features must be extracted first using the same process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce82696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” QUICK CHECK: Train vs Validation Accuracy\n",
      "==================================================\n",
      "Accuracy variables found in notebook:\n",
      "  accuracy = 0.9876 (98.76%)\n",
      "  class_accuracy = 0.9913 (99.13%)\n",
      "  train_accuracy = 0.9991 (99.91%)\n",
      "\n",
      "â“ Do you see BOTH training AND validation accuracy above?\n",
      "   If only ONE accuracy â†’ That's likely your issue!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” QUICK CHECK: Train vs Validation Accuracy\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Look for these variables in your notebook scope\n",
    "accuracy_vars = [var for var in globals().keys() if 'acc' in var.lower()]\n",
    "print(\"Accuracy variables found in notebook:\")\n",
    "for var in accuracy_vars:\n",
    "    try:\n",
    "        value = globals()[var]\n",
    "        if isinstance(value, (int, float)) and 0 <= value <= 1:\n",
    "            print(f\"  {var} = {value:.4f} ({value*100:.2f}%)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\nâ“ Do you see BOTH training AND validation accuracy above?\")\n",
    "print(\"   If only ONE accuracy â†’ That's likely your issue!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5605819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” DATA SPLIT VERIFICATION\n",
      "==================================================\n",
      "âŒ X_train/X_val not found - check variable names\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” DATA SPLIT VERIFICATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if you have train/validation data\n",
    "if 'X_train' in globals() and 'X_val' in globals():\n",
    "    print(f\"âœ… Found X_train: {len(X_train)} samples\")\n",
    "    print(f\"âœ… Found X_val: {len(X_val)} samples\")\n",
    "    \n",
    "    # Quick overlap check\n",
    "    if hasattr(X_train, '__iter__') and hasattr(X_val, '__iter__'):\n",
    "        try:\n",
    "            train_set = set(X_train) if isinstance(X_train[0], str) else set(str(x) for x in X_train)\n",
    "            val_set = set(X_val) if isinstance(X_val[0], str) else set(str(x) for x in X_val)\n",
    "            overlaps = len(train_set.intersection(val_set))\n",
    "            print(f\"ðŸ” Overlapping samples: {overlaps}\")\n",
    "            if overlaps > 0:\n",
    "                print(\"ðŸš¨ DATA LEAKAGE DETECTED!\")\n",
    "            else:\n",
    "                print(\"âœ… No overlap detected\")\n",
    "        except:\n",
    "            print(\"â“ Could not check overlap - check data types\")\n",
    "else:\n",
    "    print(\"âŒ X_train/X_val not found - check variable names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806f6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SEARCHING FOR DATA VARIABLES\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Look for common data variable names\u001b[39;00m\n\u001b[32m      5\u001b[39m data_vars = []\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvar_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” SEARCHING FOR DATA VARIABLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Look for common data variable names\n",
    "data_vars = []\n",
    "for var_name in globals().keys():\n",
    "    try:\n",
    "        var_value = globals()[var_name]\n",
    "        # Look for variables that might contain data\n",
    "        if any(keyword in var_name.lower() for keyword in ['data', 'text', 'train', 'test', 'val', 'x_', 'y_']):\n",
    "            # Skip functions, modules, and types\n",
    "            if not callable(var_value) and not isinstance(var_value, type):\n",
    "                try:\n",
    "                    length = len(var_value) if hasattr(var_value, '__len__') else 'N/A'\n",
    "                    data_vars.append((var_name, type(var_value).__name__, length))\n",
    "                except:\n",
    "                    data_vars.append((var_name, type(var_value).__name__, 'Unknown'))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Data-related variables found:\")\n",
    "for name, dtype, length in data_vars:\n",
    "    print(f\"  {name}: {dtype} (length: {length})\")\n",
    "\n",
    "# Also check for DataFrames specifically\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df_vars = [var for var in globals().keys() if isinstance(globals()[var], pd.DataFrame)]\n",
    "    print(f\"\\nDataFrame variables: {df_vars}\")\n",
    "    for df_name in df_vars:\n",
    "        df = globals()[df_name]\n",
    "        print(f\"  {df_name}: {df.shape} - columns: {list(df.columns)}\")\n",
    "except:\n",
    "    print(\"\\nNo pandas DataFrames found or pandas not imported\")\n",
    "\n",
    "# Look for any lists/arrays that might be your features/labels\n",
    "print(\"\\nLarge arrays/lists (potential datasets):\")\n",
    "for var_name in globals().keys():\n",
    "    try:\n",
    "        var_value = globals()[var_name]\n",
    "        if hasattr(var_value, '__len__') and not isinstance(var_value, (str, dict, type)):\n",
    "            length = len(var_value)\n",
    "            if length > 1000:  # Likely a dataset\n",
    "                print(f\"  {var_name}: {type(var_value).__name__} (length: {length})\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306dfcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” VALIDATION vs TRAINING ACCURACY CHECK\n",
      "============================================================\n",
      "ðŸŽ¯ TRUE VALIDATION ACCURACY: 0.9862 (98.62%)\n",
      "ðŸ“Š TRAINING ACCURACY: 0.9947 (99.47%)\n",
      "\n",
      "ðŸ“‹ COMPARISON:\n",
      "   Reported accuracy: 98.62%\n",
      "   Actual validation: 98.62%\n",
      "   Training accuracy: 99.47%\n",
      "\n",
      "âœ… GOOD: You reported validation accuracy!\n",
      "\n",
      "ðŸ“ˆ OVERFITTING ANALYSIS:\n",
      "   Training - Validation gap: 0.0085 (0.85 percentage points)\n",
      "   âœ… Good generalization\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” VALIDATION vs TRAINING ACCURACY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate the TRUE validation accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# You have these variables:\n",
    "# y_true: list (6831) - validation true labels  \n",
    "# y_pred: ndarray (6831) - validation predictions\n",
    "# train_y_pred: ndarray (27320) - training predictions\n",
    "# train_labels: list (27320) - training true labels\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"ðŸŽ¯ TRUE VALIDATION ACCURACY: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Calculate training accuracy  \n",
    "train_acc_recalc = accuracy_score(train_labels, train_y_pred)\n",
    "print(f\"ðŸ“Š TRAINING ACCURACY: {train_acc_recalc:.4f} ({train_acc_recalc*100:.2f}%)\")\n",
    "\n",
    "# Compare with what you reported\n",
    "print(f\"\\nðŸ“‹ COMPARISON:\")\n",
    "print(f\"   Reported accuracy: 98.62%\")\n",
    "print(f\"   Actual validation: {val_accuracy*100:.2f}%\")\n",
    "print(f\"   Training accuracy: {train_acc_recalc*100:.2f}%\")\n",
    "\n",
    "# Check which one matches your reported accuracy\n",
    "reported = 0.9862\n",
    "if abs(reported - val_accuracy) < 0.001:\n",
    "    print(f\"\\nâœ… GOOD: You reported validation accuracy!\")\n",
    "elif abs(reported - train_acc_recalc) < 0.001:\n",
    "    print(f\"\\nðŸš¨ PROBLEM: You reported training accuracy instead of validation!\")\n",
    "else:\n",
    "    print(f\"\\nâ“ UNCLEAR: Reported accuracy doesn't match either - investigate further\")\n",
    "\n",
    "# Calculate overfitting gap\n",
    "gap = train_acc_recalc - val_accuracy\n",
    "print(f\"\\nðŸ“ˆ OVERFITTING ANALYSIS:\")\n",
    "print(f\"   Training - Validation gap: {gap:.4f} ({gap*100:.2f} percentage points)\")\n",
    "if gap > 0.05:\n",
    "    print(\"   ðŸš¨ SEVERE OVERFITTING detected!\")\n",
    "elif gap > 0.02:\n",
    "    print(\"   âš ï¸ MODERATE OVERFITTING detected\")\n",
    "else:\n",
    "    print(\"   âœ… Good generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79851a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” MODEL RE-EVALUATION\n",
      "==================================================\n",
      "Model variables found:\n",
      "  AutoModelForSequenceClassification: <class 'type'>\n",
      "  save_model_results: <class 'function'>\n",
      "  save_trained_model: <class 'function'>\n",
      "  model_name: <class 'str'>\n",
      "  model: <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n",
      "âœ… Found model in memory\n",
      "ðŸ“Š Re-evaluating on train and validation sets...\n",
      "âš ï¸  MANUAL STEP REQUIRED:\n",
      "   Run your model.predict() on BOTH X_train and X_val\n",
      "   Then compare the accuracies!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” MODEL RE-EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if you have a trained model in memory\n",
    "model_vars = [var for var in globals().keys() if 'model' in var.lower()]\n",
    "print(\"Model variables found:\")\n",
    "for var in model_vars:\n",
    "    print(f\"  {var}: {type(globals()[var])}\")\n",
    "\n",
    "# If you have your model, let's re-evaluate it properly\n",
    "if 'model' in globals() or 'bert_model' in globals():\n",
    "    try:\n",
    "        # Try to get the model (adjust variable name as needed)\n",
    "        current_model = globals().get('model') or globals().get('bert_model')\n",
    "        \n",
    "        print(\"âœ… Found model in memory\")\n",
    "        print(\"ðŸ“Š Re-evaluating on train and validation sets...\")\n",
    "        \n",
    "        # You'll need to run your prediction code here\n",
    "        # This is a template - adjust based on your model type\n",
    "        print(\"âš ï¸  MANUAL STEP REQUIRED:\")\n",
    "        print(\"   Run your model.predict() on BOTH X_train and X_val\")\n",
    "        print(\"   Then compare the accuracies!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error accessing model: {e}\")\n",
    "else:\n",
    "    print(\"âŒ No model found in notebook scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” PROPER MODEL RE-EVALUATION\n",
      "============================================================\n",
      "ðŸ“Š Re-evaluating model on both sets...\n",
      "ðŸ” Validation set re-evaluation...\n",
      "ðŸ” Training set re-evaluation...\n",
      "\n",
      "ðŸŽ¯ FRESH EVALUATION RESULTS:\n",
      "Training Accuracy:   0.9947 (99.47%)\n",
      "Validation Accuracy: 0.9862 (98.62%)\n",
      "Accuracy Gap:        0.0085\n",
      "\n",
      "ðŸ“Š COMPARISON WITH PREVIOUS RESULTS:\n",
      "Previous training:   0.9947 (99.47%)\n",
      "Previous validation: 0.9862 (98.62%)\n",
      "New training:        0.9947 (99.47%)\n",
      "New validation:      0.9862 (98.62%)\n",
      "\n",
      "âœ… RESULTS CONSISTENT: Your original evaluation was correct!\n",
      "   The 98.62% validation accuracy is legitimate.\n",
      "\n",
      "ðŸ FINAL VERDICT:\n",
      "âœ… Your model genuinely achieves 98.62% validation accuracy\n",
      "   This is exceptionally high but appears to be legitimate\n",
      "   Your fake news dataset may be particularly well-separated\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” PROPER MODEL RE-EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# You have the model and the data, let's re-evaluate properly\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"ðŸ“Š Re-evaluating model on both sets...\")\n",
    "\n",
    "# Function to get predictions from the model\n",
    "def get_model_predictions(dataset, batch_size=16):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Get predictions\n",
    "            outputs = model(**{k: v.to(model.device) for k, v in batch.items() if k != 'labels'})\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_labels = torch.argmax(predictions, dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Re-evaluate on validation set\n",
    "print(\"ðŸ” Validation set re-evaluation...\")\n",
    "val_preds_new, val_labels_new = get_model_predictions(val_dataset)\n",
    "val_acc_new = accuracy_score(val_labels_new, val_preds_new)\n",
    "\n",
    "# Re-evaluate on training set\n",
    "print(\"ðŸ” Training set re-evaluation...\")\n",
    "train_preds_new, train_labels_new = get_model_predictions(train_dataset)\n",
    "train_acc_new = accuracy_score(train_labels_new, train_preds_new)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FRESH EVALUATION RESULTS:\")\n",
    "print(f\"Training Accuracy:   {train_acc_new:.4f} ({train_acc_new*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc_new:.4f} ({val_acc_new*100:.2f}%)\")\n",
    "print(f\"Accuracy Gap:        {train_acc_new - val_acc_new:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š COMPARISON WITH PREVIOUS RESULTS:\")\n",
    "print(f\"Previous training:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Previous validation: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"New training:        {train_acc_new:.4f} ({train_acc_new*100:.2f}%)\")\n",
    "print(f\"New validation:      {val_acc_new:.4f} ({val_acc_new*100:.2f}%)\")\n",
    "\n",
    "# Check consistency\n",
    "if abs(val_acc_new - accuracy) < 0.001 and abs(train_acc_new - train_accuracy) < 0.001:\n",
    "    print(f\"\\nâœ… RESULTS CONSISTENT: Your original evaluation was correct!\")\n",
    "    print(f\"   The 98.62% validation accuracy is legitimate.\")\n",
    "else:\n",
    "    print(f\"\\nâ“ INCONSISTENCY DETECTED: Results don't match - investigate further\")\n",
    "\n",
    "# Final verdict\n",
    "print(f\"\\nðŸ FINAL VERDICT:\")\n",
    "if val_acc_new > 0.98:\n",
    "    print(f\"âœ… Your model genuinely achieves {val_acc_new*100:.2f}% validation accuracy\")\n",
    "    print(f\"   This is exceptionally high but appears to be legitimate\")\n",
    "    print(f\"   Your fake news dataset may be particularly well-separated\")\n",
    "else:\n",
    "    print(f\"ðŸ“Š More reasonable validation accuracy: {val_acc_new*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89293ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TEST SET PREDICTION ANALYSIS\n",
      "==================================================\n",
      "ðŸ“Š Prediction Confidence Analysis:\n",
      "Mean confidence: 0.9973\n",
      "Median confidence: 0.9998\n",
      "High confidence (>0.9): 9925/9983 (99.4%)\n",
      "Low confidence (<0.7): 15/9983 (0.2%)\n",
      "\n",
      "ðŸ“ˆ Predicted Class Distribution:\n",
      "Predicted Fake (0): 5028 (50.4%)\n",
      "Predicted Real (1): 4955 (49.6%)\n",
      "\n",
      "ðŸ”„ Distribution Comparison:\n",
      "Training - Fake: 51.4%, Real: 48.6%\n",
      "Test predictions - Fake: 50.4%, Real: 49.6%\n",
      "âœ… Similar distributions - accuracy should be close to validation\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” TEST SET PREDICTION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# You have these test variables:\n",
    "# test_pred_labels: ndarray (9983) - your predictions\n",
    "# test_labels: list (9983) - if you have true labels somehow\n",
    "# test_pred_probs: ndarray (9983) - prediction probabilities\n",
    "\n",
    "# Check confidence distribution\n",
    "confidence = np.max(test_pred_probs, axis=1)\n",
    "print(f\"ðŸ“Š Prediction Confidence Analysis:\")\n",
    "print(f\"Mean confidence: {confidence.mean():.4f}\")\n",
    "print(f\"Median confidence: {np.median(confidence):.4f}\")\n",
    "print(f\"High confidence (>0.9): {(confidence > 0.9).sum()}/{len(confidence)} ({(confidence > 0.9).mean()*100:.1f}%)\")\n",
    "print(f\"Low confidence (<0.7): {(confidence < 0.7).sum()}/{len(confidence)} ({(confidence < 0.7).mean()*100:.1f}%)\")\n",
    "\n",
    "# Class distribution in predictions\n",
    "pred_distribution = np.bincount(test_pred_labels)\n",
    "print(f\"\\nðŸ“ˆ Predicted Class Distribution:\")\n",
    "print(f\"Predicted Fake (0): {pred_distribution[0]} ({pred_distribution[0]/len(test_pred_labels)*100:.1f}%)\")\n",
    "print(f\"Predicted Real (1): {pred_distribution[1]} ({pred_distribution[1]/len(test_pred_labels)*100:.1f}%)\")\n",
    "\n",
    "# Compare with training distribution\n",
    "train_dist = np.bincount(train_labels)\n",
    "print(f\"\\nðŸ”„ Distribution Comparison:\")\n",
    "print(f\"Training - Fake: {train_dist[0]/len(train_labels)*100:.1f}%, Real: {train_dist[1]/len(train_labels)*100:.1f}%\")\n",
    "print(f\"Test predictions - Fake: {pred_distribution[0]/len(test_pred_labels)*100:.1f}%, Real: {pred_distribution[1]/len(test_pred_labels)*100:.1f}%\")\n",
    "\n",
    "# If distributions are very different, accuracy might be different\n",
    "dist_diff = abs((pred_distribution[0]/len(test_pred_labels)) - (train_dist[0]/len(train_labels)))\n",
    "if dist_diff > 0.1:\n",
    "    print(\"âš ï¸  Large distribution shift detected - accuracy may be different\")\n",
    "else:\n",
    "    print(\"âœ… Similar distributions - accuracy should be close to validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
