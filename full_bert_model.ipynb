{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bert-model-header",
   "metadata": {},
   "source": [
    "# BERT Model: Fine-tuned Transformer for Fake News Classification\n",
    "\n",
    "This notebook implements a fine-tuned BERT model for binary classification of fake vs real news articles.\n",
    "\n",
    "## ðŸ”§ Steps:\n",
    "1. Import libraries and load data\n",
    "2. Minimal preprocessing (preserve structure for BERT)\n",
    "3. BERT tokenization and encoding\n",
    "4. Model setup and fine-tuning\n",
    "5. Training with validation\n",
    "6. Evaluation and comparison\n",
    "\n",
    "## âœ… Purpose:\n",
    "Achieve state-of-the-art performance using transformer architecture (~85-90% accuracy expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) for M4 acceleration\n",
      "PyTorch version: 2.7.0\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve, auc, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_eval import save_model_results, save_trained_model\n",
    "\n",
    "\n",
    "# Import our preprocessing functions\n",
    "from preprocess import load_and_parse_data, create_train_validation_split\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available for M4\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal Performance Shaders) for M4 acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU (this will be slower)\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-section",
   "metadata": {},
   "source": [
    "## 2. Load and Parse Data\n",
    "\n",
    "Using our preprocessing module to load the tab-separated data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/training_data_lowercase.csv...\n",
      "Loaded 34151 articles\n",
      "Loading test data...\n",
      "Loading data from data/testing_data_lowercase_nolabels.csv...\n",
      "Loaded 9983 articles\n",
      "Training data shape: (34151, 2)\n",
      "Test data shape: (9983, 2)\n",
      "Label distribution: Counter({0: 17571, 1: 16580})\n",
      "\n",
      "Sample training data:\n",
      "Label 0: drunk bragging trump staffer started russian collusion investigation...\n",
      "Label 0: sheriff david clarke becomes an internet joke for threatening to poke people â€šin...\n",
      "Label 0: trump is so obsessed he even has obamaâ€šs name coded into his website (images)...\n"
     ]
    }
   ],
   "source": [
    "# Load data using our preprocessing function\n",
    "print(\"Loading training data...\")\n",
    "train_data = load_and_parse_data('data/training_data_lowercase.csv')\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data = load_and_parse_data('data/testing_data_lowercase_nolabels.csv')\n",
    "\n",
    "# Convert to DataFrames for easier handling\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Label distribution: {Counter(train_df['label'])}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nSample training data:\")\n",
    "for i in range(3):\n",
    "    print(f\"Label {train_df.iloc[i]['label']}: {train_df.iloc[i]['text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-section",
   "metadata": {},
   "source": [
    "## 3. Minimal Text Preprocessing\n",
    "\n",
    "BERT works best with minimal preprocessing - we'll only clean essential formatting issues while preserving punctuation and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length statistics (words):\n",
      "Mean: 11.7\n",
      "Median: 11.0\n",
      "95th percentile: 19.0\n",
      "99th percentile: 24.0\n",
      "\n",
      "Using max_length: 39\n"
     ]
    }
   ],
   "source": [
    "def minimal_bert_cleaning(text):\n",
    "    \"\"\"Minimal cleaning for BERT - preserve original structure\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and remove excessive whitespace only\n",
    "    text = str(text).strip()\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply minimal cleaning\n",
    "train_df['clean_text'] = train_df['text'].apply(minimal_bert_cleaning)\n",
    "test_df['clean_text'] = test_df['text'].apply(minimal_bert_cleaning)\n",
    "\n",
    "# Remove any empty texts\n",
    "train_df = train_df[train_df['clean_text'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# Analyze text lengths for optimal max_length\n",
    "text_lengths = train_df['clean_text'].str.split().str.len()\n",
    "print(f\"Text length statistics (words):\")\n",
    "print(f\"Mean: {text_lengths.mean():.1f}\")\n",
    "print(f\"Median: {text_lengths.median():.1f}\")\n",
    "print(f\"95th percentile: {text_lengths.quantile(0.95):.1f}\")\n",
    "print(f\"99th percentile: {text_lengths.quantile(0.99):.1f}\")\n",
    "\n",
    "# Choose max_length based on 95th percentile + buffer\n",
    "max_length = min(256, int(text_lengths.quantile(0.95)) + 20)\n",
    "print(f\"\\nUsing max_length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenization-section",
   "metadata": {},
   "source": [
    "## 4. BERT Tokenization and Dataset Creation\n",
    "\n",
    "Setting up BERT tokenizer and creating PyTorch datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tokenization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: bert-base-uncased\n",
      "Tokenizer vocabulary size: 30522\n",
      "Train set: 27320 samples\n",
      "Validation set: 6831 samples\n",
      "Train label distribution: Counter({0: 14056, 1: 13264})\n",
      "Validation label distribution: Counter({0: 3515, 1: 3316})\n",
      "\n",
      "Dataset sizes:\n",
      "Training: 27320\n",
      "Validation: 6831\n",
      "\n",
      "Sample tokenization shape:\n",
      "Input IDs: torch.Size([39])\n",
      "Attention mask: torch.Size([39])\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Using model: {model_name}\")\n",
    "print(f\"Tokenizer vocabulary size: {len(tokenizer.vocab)}\")\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"Custom dataset for news classification\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create train/validation split using our preprocessing function\n",
    "train_texts, val_texts, train_labels, val_labels = create_train_validation_split(\n",
    "    [{'text': text, 'label': label} for text, label in zip(train_df['clean_text'], train_df['label'])],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NewsDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = NewsDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Training: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "\n",
    "# Test tokenization on a sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample tokenization shape:\")\n",
    "print(f\"Input IDs: {sample['input_ids'].shape}\")\n",
    "print(f\"Attention mask: {sample['attention_mask'].shape}\")\n",
    "print(f\"Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-setup-section",
   "metadata": {},
   "source": [
    "## 5. Model Setup and Training Configuration\n",
    "\n",
    "Loading pre-trained BERT and setting up training parameters for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "model-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 109,483,778 parameters\n",
      "Model device: mps:0\n",
      "\n",
      "Training setup complete!\n",
      "Batch size: 16\n",
      "Number of epochs: 3\n",
      "Learning rate: 5e-05\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded with {model.num_parameters():,} parameters\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert_results',\n",
    "    num_train_epochs=3,              # Start with 3 epochs\n",
    "    per_device_train_batch_size=16,  # Adjust based on memory\n",
    "    per_device_eval_batch_size=32,   # Larger batch for evaluation\n",
    "    warmup_steps=500,                # Warmup for learning rate\n",
    "    weight_decay=0.01,               # Regularization\n",
    "    logging_dir='./bert_logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,                  # Evaluate every 500 steps\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=None,                  # Disable wandb/tensorboard\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define metrics computation\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining setup complete!\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Fine-tuning BERT on our fake news dataset with validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BERT fine-tuning...\n",
      "Training on 27320 samples\n",
      "Validating on 6831 samples\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3500' max='5124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3500/5124 09:40 < 04:29, 6.03 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.092912</td>\n",
       "      <td>0.974381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.071244</td>\n",
       "      <td>0.976577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.978920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.082490</td>\n",
       "      <td>0.982872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.053822</td>\n",
       "      <td>0.986239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.062932</td>\n",
       "      <td>0.985214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.985361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Training time: 9.76 minutes\n",
      "Final training loss: 0.0901\n",
      "\n",
      "Model saved to './bert_fine_tuned'\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting BERT fine-tuning...\")\n",
    "print(f\"Training on {len(train_dataset)} samples\")\n",
    "print(f\"Validating on {len(val_dataset)} samples\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Final training loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model('./bert_fine_tuned')\n",
    "print(\"\\nModel saved to './bert_fine_tuned'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Comprehensive evaluation with accuracy, classification report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Model Results:\n",
      "Validation Accuracy: 0.9862 (98.62%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Fake (0)       0.99      0.98      0.99      3515\n",
      "    Real (1)       0.98      0.99      0.99      3316\n",
      "\n",
      "    accuracy                           0.99      6831\n",
      "   macro avg       0.99      0.99      0.99      6831\n",
      "weighted avg       0.99      0.99      0.99      6831\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Performance by Class:\n",
      "Fake (0): 0.9829 (98.29%)\n",
      "Real (1): 0.9897 (98.97%)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(val_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = val_labels\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nBERT Model Results:\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "class_names = ['Fake (0)', 'Real (1)']\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('BERT Model - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Performance by class\n",
    "print(\"\\nðŸ“ˆ Performance by Class:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = np.array(y_true) == i\n",
    "    class_accuracy = accuracy_score(np.array(y_true)[class_mask], y_pred[class_mask])\n",
    "    print(f\"{class_name}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "train_predictions = trainer.predict(train_dataset)\n",
    "train_y_pred = np.argmax(train_predictions.predictions, axis=1)\n",
    "train_accuracy = accuracy_score(train_labels, train_y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-model-results-section",
   "metadata": {},
   "source": [
    "## 8. Save Model Results\n",
    "\n",
    "Save the model evaluation results using the model_eval module for consistency with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save-model-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results/full_bert_model_results.json\n",
      "Model: Full BERT Fine-tuned\n",
      "Accuracy: 0.9862 (98.62%)\n",
      "Training Time: 9.76 minutes\n",
      "Model results saved successfully!\n",
      "Model: Full BERT Fine-tuned\n",
      "Training Accuracy: 0.9947\n",
      "Validation Accuracy: 0.9862\n",
      "Training Time: 9.76 minutes\n",
      "Model Parameters: 109,483,778\n",
      "Device Used: mps\n"
     ]
    }
   ],
   "source": [
    "# Calculate additional metrics for save_model_results\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred).tolist()\n",
    "class_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Save results using the model_eval module (similar to other models)\n",
    "save_model_results(\n",
    "    model_name=\"full_bert_model\",\n",
    "    display_name=\"Full BERT Fine-tuned\",\n",
    "    accuracy=accuracy,\n",
    "    training_time_minutes=training_time/60,  # Already calculated in your training section\n",
    "    model_architecture=f\"BERT-base-uncased fine-tuned ({model.num_parameters():,} parameters)\",\n",
    "    preprocessing_type=\"minimal_cleaning\",\n",
    "    train_accuracy=train_accuracy,\n",
    "    test_accuracy=accuracy,  # Using validation accuracy as test accuracy\n",
    "    hyperparameters={\n",
    "        \"bert_model\": model_name,  # \"bert-base-uncased\"\n",
    "        \"max_length\": max_length,\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"weight_decay\": training_args.weight_decay,\n",
    "        \"warmup_steps\": training_args.warmup_steps,\n",
    "        \"early_stopping_patience\": 2\n",
    "    },\n",
    "    dataset_info={\n",
    "        \"training_samples\": len(train_dataset),\n",
    "        \"validation_samples\": len(val_dataset),\n",
    "        \"max_sequence_length\": max_length,\n",
    "        \"total_parameters\": model.num_parameters(),\n",
    "        \"vocab_size\": len(tokenizer.vocab),\n",
    "        \"device\": str(device)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Model results saved successfully!\")\n",
    "print(f\"Model: Full BERT Fine-tuned\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"Model Parameters: {model.num_parameters():,}\")\n",
    "print(f\"Device Used: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-predictions-section",
   "metadata": {},
   "source": [
    "## Test Set Predictions\n",
    "\n",
    "Generate predictions for the test set and save to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test set predictions...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9983 test samples...\n",
      "Logits shape: (9983, 2)\n",
      "Predictions shape: (9983,)\n",
      "Probabilities shape: (9983, 2)\n",
      "âœ… Saved 9983 predictions to prediction/full_bert_predictions.csv\n",
      "\n",
      "Prediction Summary:\n",
      "   Predicted Fake (0): 5028 articles\n",
      "   Predicted Real (1): 4955 articles\n",
      "   Fake prediction rate: 50.37%\n",
      "   Real prediction rate: 49.63%\n",
      "\n",
      "Confidence Statistics:\n",
      "   Mean confidence: 0.9973\n",
      "   Median confidence: 0.9998\n",
      "   Min confidence: 0.5083\n",
      "   Max confidence: 0.9999\n",
      "\n",
      "ðŸ“‹ First 5 predictions (text truncated for display):\n",
      "predicted_label | title_preview\n",
      "--------------------------------------------------\n",
      "             0 | wow! chicago protester caught on camera admits vio...\n",
      "             1 | germany's fdp look to fill schaeuble's big shoes\n",
      "             0 | mi school sends welcome back packet warning kids a...\n",
      "             1 | u.n. seeks 'massive' aid boost amid rohingya 'emer...\n",
      "             0 | did oprah just leave â€šnastyâ€š hillary wishing she w...\n",
      "\n",
      "âœ… Test set predictions completed successfully!\n",
      "   Output file: prediction/full_bert_predictions.csv\n",
      "   Format: predicted_label, title (no headers)\n"
     ]
    }
   ],
   "source": [
    "## Test Set Predictions\n",
    "# Generate predictions for the test set and save to CSV with specified format:\n",
    "# Column 1: predicted_label\n",
    "# Column 2: title (text content) \n",
    "\n",
    "print(\"Generating test set predictions...\")\n",
    "\n",
    "# Create test dataset\n",
    "test_texts = test_df['clean_text'].tolist()\n",
    "test_labels = [0] * len(test_texts)  # Dummy labels for dataset creation\n",
    "test_dataset = NewsDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "\n",
    "# Generate predictions using the trained model\n",
    "test_predictions = trainer.predict(test_dataset)\n",
    "test_logits = test_predictions.predictions\n",
    "test_pred_labels = np.argmax(test_logits, axis=1)\n",
    "\n",
    "# Convert logits to probabilities using softmax (for confidence statistics only)\n",
    "from scipy.special import softmax\n",
    "test_pred_probs = softmax(test_logits, axis=1)\n",
    "\n",
    "print(f\"Processing {len(test_texts)} test samples...\")\n",
    "print(f\"Logits shape: {test_logits.shape}\")\n",
    "print(f\"Predictions shape: {test_pred_labels.shape}\")\n",
    "print(f\"Probabilities shape: {test_pred_probs.shape}\")\n",
    "\n",
    "# Create submission file with specified column order:\n",
    "# predicted_label, title (no headers)\n",
    "output_file = 'prediction/full_bert_predictions.csv'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    # Write each prediction with proper CSV formatting\n",
    "    for i in range(len(test_texts)):\n",
    "        # Get prediction\n",
    "        pred_label = test_pred_labels[i]\n",
    "        \n",
    "        # Handle text formatting for CSV (escape quotes and commas)\n",
    "        title_text = str(test_texts[i])\n",
    "        # Escape quotes by doubling them\n",
    "        title_text = title_text.replace('\"', '\"\"')\n",
    "        # Wrap in quotes if contains comma, quote, or newline\n",
    "        if ',' in title_text or '\"' in title_text or '\\n' in title_text:\n",
    "            title_text = f'\"{title_text}\"'\n",
    "        \n",
    "        # Write row: predicted_label, title\n",
    "        f.write(f'{pred_label},{title_text}\\n')\n",
    "\n",
    "print(f\"âœ… Saved {len(test_pred_labels)} predictions to {output_file}\")\n",
    "\n",
    "# Display prediction summary\n",
    "print(f\"\\nPrediction Summary:\")\n",
    "print(f\"   Predicted Fake (0): {np.sum(test_pred_labels == 0)} articles\")\n",
    "print(f\"   Predicted Real (1): {np.sum(test_pred_labels == 1)} articles\")\n",
    "print(f\"   Fake prediction rate: {np.sum(test_pred_labels == 0) / len(test_pred_labels) * 100:.2f}%\")\n",
    "print(f\"   Real prediction rate: {np.sum(test_pred_labels == 1) / len(test_pred_labels) * 100:.2f}%\")\n",
    "\n",
    "# Display confidence statistics\n",
    "confidence_scores = np.max(test_pred_probs, axis=1)\n",
    "print(f\"\\nConfidence Statistics:\")\n",
    "print(f\"   Mean confidence: {confidence_scores.mean():.4f}\")\n",
    "print(f\"   Median confidence: {np.median(confidence_scores):.4f}\")\n",
    "print(f\"   Min confidence: {confidence_scores.min():.4f}\")\n",
    "print(f\"   Max confidence: {confidence_scores.max():.4f}\")\n",
    "\n",
    "# Display first few rows for verification (with truncated text for readability)\n",
    "print(f\"\\nðŸ“‹ First 5 predictions (text truncated for display):\")\n",
    "print(\"predicted_label | title_preview\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(5, len(test_pred_labels))):\n",
    "    title_preview = str(test_texts[i])[:50].replace('\\n', ' ')\n",
    "    if len(str(test_texts[i])) > 50:\n",
    "        title_preview += \"...\"\n",
    "    print(f\"{test_pred_labels[i]:>14} | {title_preview}\")\n",
    "\n",
    "print(f\"\\nâœ… Test set predictions completed successfully!\")\n",
    "print(f\"   Output file: {output_file}\")\n",
    "print(f\"   Format: predicted_label, title (no headers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae4cee",
   "metadata": {},
   "source": [
    "## Save model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90ab6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved: trained_models/full_bert_20250530_133543.joblib\n",
      "Trained model saved successfully!\n",
      "Note: For new predictions, BERT features must be extracted first using the same process.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained classifier (Note: BERT embeddings would need to be re-extracted for new data)\\n\n",
    "save_trained_model(model, model_name=\"full_bert\")\n",
    "\n",
    "print(\"Trained model saved successfully!\")\n",
    "print(\"Note: For new predictions, BERT features must be extracted first using the same process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce82696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” QUICK CHECK: Train vs Validation Accuracy\n",
      "==================================================\n",
      "Accuracy variables found in notebook:\n",
      "  accuracy = 0.9862 (98.62%)\n",
      "  class_accuracy = 0.9897 (98.97%)\n",
      "  train_accuracy = 0.9947 (99.47%)\n",
      "  baseline_accuracy = 0.7000 (70.00%)\n",
      "  bin_accuracy = 0.9905 (99.05%)\n",
      "  acc = 0.9862 (98.62%)\n",
      "  baseline_acc = 0.9290 (92.90%)\n",
      "  simple_bert_acc = 0.9587 (95.87%)\n",
      "  boot_accuracy = 0.9859 (98.59%)\n",
      "\n",
      "â“ Do you see BOTH training AND validation accuracy above?\n",
      "   If only ONE accuracy â†’ That's likely your issue!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” QUICK CHECK: Train vs Validation Accuracy\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Look for these variables in your notebook scope\n",
    "accuracy_vars = [var for var in globals().keys() if 'acc' in var.lower()]\n",
    "print(\"Accuracy variables found in notebook:\")\n",
    "for var in accuracy_vars:\n",
    "    try:\n",
    "        value = globals()[var]\n",
    "        if isinstance(value, (int, float)) and 0 <= value <= 1:\n",
    "            print(f\"  {var} = {value:.4f} ({value*100:.2f}%)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\nâ“ Do you see BOTH training AND validation accuracy above?\")\n",
    "print(\"   If only ONE accuracy â†’ That's likely your issue!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5605819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” DATA SPLIT VERIFICATION\n",
      "==================================================\n",
      "âŒ X_train/X_val not found - check variable names\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” DATA SPLIT VERIFICATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if you have train/validation data\n",
    "if 'X_train' in globals() and 'X_val' in globals():\n",
    "    print(f\"âœ… Found X_train: {len(X_train)} samples\")\n",
    "    print(f\"âœ… Found X_val: {len(X_val)} samples\")\n",
    "    \n",
    "    # Quick overlap check\n",
    "    if hasattr(X_train, '__iter__') and hasattr(X_val, '__iter__'):\n",
    "        try:\n",
    "            train_set = set(X_train) if isinstance(X_train[0], str) else set(str(x) for x in X_train)\n",
    "            val_set = set(X_val) if isinstance(X_val[0], str) else set(str(x) for x in X_val)\n",
    "            overlaps = len(train_set.intersection(val_set))\n",
    "            print(f\"ðŸ” Overlapping samples: {overlaps}\")\n",
    "            if overlaps > 0:\n",
    "                print(\"ðŸš¨ DATA LEAKAGE DETECTED!\")\n",
    "            else:\n",
    "                print(\"âœ… No overlap detected\")\n",
    "        except:\n",
    "            print(\"â“ Could not check overlap - check data types\")\n",
    "else:\n",
    "    print(\"âŒ X_train/X_val not found - check variable names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "806f6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SEARCHING FOR DATA VARIABLES\n",
      "==================================================\n",
      "Data-related variables found:\n",
      "  train_data: list (length: 34151)\n",
      "  test_data: list (length: 9983)\n",
      "  train_df: DataFrame (length: 34151)\n",
      "  test_df: DataFrame (length: 9983)\n",
      "  text_lengths: Series (length: 34151)\n",
      "  max_length: int (length: N/A)\n",
      "  train_texts: list (length: 27320)\n",
      "  val_texts: list (length: 6831)\n",
      "  train_labels: list (length: 27320)\n",
      "  val_labels: list (length: 6831)\n",
      "  train_dataset: NewsDataset (length: 27320)\n",
      "  val_dataset: NewsDataset (length: 6831)\n",
      "  training_args: TrainingArguments (length: N/A)\n",
      "  trainer: Trainer (length: N/A)\n",
      "  train_result: TrainOutput (length: 3)\n",
      "  training_time: float (length: N/A)\n",
      "  y_pred: ndarray (length: 6831)\n",
      "  y_true: list (length: 6831)\n",
      "  train_predictions: PredictionOutput (length: 3)\n",
      "  train_y_pred: ndarray (length: 27320)\n",
      "  train_accuracy: float (length: N/A)\n",
      "  train_losses: list (length: 1)\n",
      "  eval_accuracies: list (length: 7)\n",
      "  var_value: str (length: 8)\n",
      "  y_prob: ndarray (length: 6831)\n",
      "  text_sample: str (length: 95)\n",
      "  boot_y_true: ndarray (length: 6831)\n",
      "  boot_y_pred: ndarray (length: 6831)\n",
      "  test_texts: list (length: 9983)\n",
      "  test_labels: list (length: 9983)\n",
      "  test_dataset: NewsDataset (length: 9983)\n",
      "  test_predictions: PredictionOutput (length: 3)\n",
      "  test_logits: ndarray (length: 9983)\n",
      "  test_pred_labels: ndarray (length: 9983)\n",
      "  test_pred_probs: ndarray (length: 9983)\n",
      "  title_text: str (length: 142)\n",
      "  accuracy_vars: list (length: 13)\n",
      "  value: float (length: N/A)\n",
      "  data_vars: list (length: 38)\n",
      "\n",
      "DataFrame variables: ['train_df', 'test_df', 'df']\n",
      "  train_df: (34151, 3) - columns: ['label', 'text', 'clean_text']\n",
      "  test_df: (9983, 3) - columns: ['label', 'text', 'clean_text']\n",
      "  df: (9983, 3) - columns: ['label', 'text', 'clean_text']\n",
      "\n",
      "Large arrays/lists (potential datasets):\n",
      "  train_data: list (length: 34151)\n",
      "  test_data: list (length: 9983)\n",
      "  train_df: DataFrame (length: 34151)\n",
      "  test_df: DataFrame (length: 9983)\n",
      "  text_lengths: Series (length: 34151)\n",
      "  tokenizer: BertTokenizerFast (length: 30522)\n",
      "  train_texts: list (length: 27320)\n",
      "  val_texts: list (length: 6831)\n",
      "  train_labels: list (length: 27320)\n",
      "  val_labels: list (length: 6831)\n",
      "  train_dataset: NewsDataset (length: 27320)\n",
      "  val_dataset: NewsDataset (length: 6831)\n",
      "  y_pred: ndarray (length: 6831)\n",
      "  y_true: list (length: 6831)\n",
      "  class_mask: ndarray (length: 6831)\n",
      "  train_y_pred: ndarray (length: 27320)\n",
      "  y_prob: ndarray (length: 6831)\n",
      "  precision_curve: ndarray (length: 5188)\n",
      "  recall_curve: ndarray (length: 5188)\n",
      "  pr_thresholds: ndarray (length: 5187)\n",
      "  confidence_scores: ndarray (length: 9983)\n",
      "  correct_predictions: ndarray (length: 6831)\n",
      "  correct_confidence: ndarray (length: 6737)\n",
      "  digitized: ndarray (length: 6831)\n",
      "  mask: ndarray (length: 6831)\n",
      "  indices: ndarray (length: 6831)\n",
      "  boot_y_true: ndarray (length: 6831)\n",
      "  boot_y_pred: ndarray (length: 6831)\n",
      "  test_texts: list (length: 9983)\n",
      "  test_labels: list (length: 9983)\n",
      "  test_dataset: NewsDataset (length: 9983)\n",
      "  test_logits: ndarray (length: 9983)\n",
      "  test_pred_labels: ndarray (length: 9983)\n",
      "  test_pred_probs: ndarray (length: 9983)\n",
      "  df: DataFrame (length: 9983)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” SEARCHING FOR DATA VARIABLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Look for common data variable names\n",
    "data_vars = []\n",
    "for var_name in globals().keys():\n",
    "    try:\n",
    "        var_value = globals()[var_name]\n",
    "        # Look for variables that might contain data\n",
    "        if any(keyword in var_name.lower() for keyword in ['data', 'text', 'train', 'test', 'val', 'x_', 'y_']):\n",
    "            # Skip functions, modules, and types\n",
    "            if not callable(var_value) and not isinstance(var_value, type):\n",
    "                try:\n",
    "                    length = len(var_value) if hasattr(var_value, '__len__') else 'N/A'\n",
    "                    data_vars.append((var_name, type(var_value).__name__, length))\n",
    "                except:\n",
    "                    data_vars.append((var_name, type(var_value).__name__, 'Unknown'))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Data-related variables found:\")\n",
    "for name, dtype, length in data_vars:\n",
    "    print(f\"  {name}: {dtype} (length: {length})\")\n",
    "\n",
    "# Also check for DataFrames specifically\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df_vars = [var for var in globals().keys() if isinstance(globals()[var], pd.DataFrame)]\n",
    "    print(f\"\\nDataFrame variables: {df_vars}\")\n",
    "    for df_name in df_vars:\n",
    "        df = globals()[df_name]\n",
    "        print(f\"  {df_name}: {df.shape} - columns: {list(df.columns)}\")\n",
    "except:\n",
    "    print(\"\\nNo pandas DataFrames found or pandas not imported\")\n",
    "\n",
    "# Look for any lists/arrays that might be your features/labels\n",
    "print(\"\\nLarge arrays/lists (potential datasets):\")\n",
    "for var_name in globals().keys():\n",
    "    try:\n",
    "        var_value = globals()[var_name]\n",
    "        if hasattr(var_value, '__len__') and not isinstance(var_value, (str, dict, type)):\n",
    "            length = len(var_value)\n",
    "            if length > 1000:  # Likely a dataset\n",
    "                print(f\"  {var_name}: {type(var_value).__name__} (length: {length})\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "306dfcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” VALIDATION vs TRAINING ACCURACY CHECK\n",
      "============================================================\n",
      "ðŸŽ¯ TRUE VALIDATION ACCURACY: 0.9862 (98.62%)\n",
      "ðŸ“Š TRAINING ACCURACY: 0.9947 (99.47%)\n",
      "\n",
      "ðŸ“‹ COMPARISON:\n",
      "   Reported accuracy: 98.62%\n",
      "   Actual validation: 98.62%\n",
      "   Training accuracy: 99.47%\n",
      "\n",
      "âœ… GOOD: You reported validation accuracy!\n",
      "\n",
      "ðŸ“ˆ OVERFITTING ANALYSIS:\n",
      "   Training - Validation gap: 0.0085 (0.85 percentage points)\n",
      "   âœ… Good generalization\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” VALIDATION vs TRAINING ACCURACY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate the TRUE validation accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# You have these variables:\n",
    "# y_true: list (6831) - validation true labels  \n",
    "# y_pred: ndarray (6831) - validation predictions\n",
    "# train_y_pred: ndarray (27320) - training predictions\n",
    "# train_labels: list (27320) - training true labels\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"ðŸŽ¯ TRUE VALIDATION ACCURACY: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Calculate training accuracy  \n",
    "train_acc_recalc = accuracy_score(train_labels, train_y_pred)\n",
    "print(f\"ðŸ“Š TRAINING ACCURACY: {train_acc_recalc:.4f} ({train_acc_recalc*100:.2f}%)\")\n",
    "\n",
    "# Compare with what you reported\n",
    "print(f\"\\nðŸ“‹ COMPARISON:\")\n",
    "print(f\"   Reported accuracy: 98.62%\")\n",
    "print(f\"   Actual validation: {val_accuracy*100:.2f}%\")\n",
    "print(f\"   Training accuracy: {train_acc_recalc*100:.2f}%\")\n",
    "\n",
    "# Check which one matches your reported accuracy\n",
    "reported = 0.9862\n",
    "if abs(reported - val_accuracy) < 0.001:\n",
    "    print(f\"\\nâœ… GOOD: You reported validation accuracy!\")\n",
    "elif abs(reported - train_acc_recalc) < 0.001:\n",
    "    print(f\"\\nðŸš¨ PROBLEM: You reported training accuracy instead of validation!\")\n",
    "else:\n",
    "    print(f\"\\nâ“ UNCLEAR: Reported accuracy doesn't match either - investigate further\")\n",
    "\n",
    "# Calculate overfitting gap\n",
    "gap = train_acc_recalc - val_accuracy\n",
    "print(f\"\\nðŸ“ˆ OVERFITTING ANALYSIS:\")\n",
    "print(f\"   Training - Validation gap: {gap:.4f} ({gap*100:.2f} percentage points)\")\n",
    "if gap > 0.05:\n",
    "    print(\"   ðŸš¨ SEVERE OVERFITTING detected!\")\n",
    "elif gap > 0.02:\n",
    "    print(\"   âš ï¸ MODERATE OVERFITTING detected\")\n",
    "else:\n",
    "    print(\"   âœ… Good generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79851a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” MODEL RE-EVALUATION\n",
      "==================================================\n",
      "Model variables found:\n",
      "  AutoModelForSequenceClassification: <class 'type'>\n",
      "  save_model_results: <class 'function'>\n",
      "  save_trained_model: <class 'function'>\n",
      "  model_name: <class 'str'>\n",
      "  model: <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n",
      "âœ… Found model in memory\n",
      "ðŸ“Š Re-evaluating on train and validation sets...\n",
      "âš ï¸  MANUAL STEP REQUIRED:\n",
      "   Run your model.predict() on BOTH X_train and X_val\n",
      "   Then compare the accuracies!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” MODEL RE-EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if you have a trained model in memory\n",
    "model_vars = [var for var in globals().keys() if 'model' in var.lower()]\n",
    "print(\"Model variables found:\")\n",
    "for var in model_vars:\n",
    "    print(f\"  {var}: {type(globals()[var])}\")\n",
    "\n",
    "# If you have your model, let's re-evaluate it properly\n",
    "if 'model' in globals() or 'bert_model' in globals():\n",
    "    try:\n",
    "        # Try to get the model (adjust variable name as needed)\n",
    "        current_model = globals().get('model') or globals().get('bert_model')\n",
    "        \n",
    "        print(\"âœ… Found model in memory\")\n",
    "        print(\"ðŸ“Š Re-evaluating on train and validation sets...\")\n",
    "        \n",
    "        # You'll need to run your prediction code here\n",
    "        # This is a template - adjust based on your model type\n",
    "        print(\"âš ï¸  MANUAL STEP REQUIRED:\")\n",
    "        print(\"   Run your model.predict() on BOTH X_train and X_val\")\n",
    "        print(\"   Then compare the accuracies!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error accessing model: {e}\")\n",
    "else:\n",
    "    print(\"âŒ No model found in notebook scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31be991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” PROPER MODEL RE-EVALUATION\n",
      "============================================================\n",
      "ðŸ“Š Re-evaluating model on both sets...\n",
      "ðŸ” Validation set re-evaluation...\n",
      "ðŸ” Training set re-evaluation...\n",
      "\n",
      "ðŸŽ¯ FRESH EVALUATION RESULTS:\n",
      "Training Accuracy:   0.9947 (99.47%)\n",
      "Validation Accuracy: 0.9862 (98.62%)\n",
      "Accuracy Gap:        0.0085\n",
      "\n",
      "ðŸ“Š COMPARISON WITH PREVIOUS RESULTS:\n",
      "Previous training:   0.9947 (99.47%)\n",
      "Previous validation: 0.9862 (98.62%)\n",
      "New training:        0.9947 (99.47%)\n",
      "New validation:      0.9862 (98.62%)\n",
      "\n",
      "âœ… RESULTS CONSISTENT: Your original evaluation was correct!\n",
      "   The 98.62% validation accuracy is legitimate.\n",
      "\n",
      "ðŸ FINAL VERDICT:\n",
      "âœ… Your model genuinely achieves 98.62% validation accuracy\n",
      "   This is exceptionally high but appears to be legitimate\n",
      "   Your fake news dataset may be particularly well-separated\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” PROPER MODEL RE-EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# You have the model and the data, let's re-evaluate properly\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"ðŸ“Š Re-evaluating model on both sets...\")\n",
    "\n",
    "# Function to get predictions from the model\n",
    "def get_model_predictions(dataset, batch_size=16):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Get predictions\n",
    "            outputs = model(**{k: v.to(model.device) for k, v in batch.items() if k != 'labels'})\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_labels = torch.argmax(predictions, dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Re-evaluate on validation set\n",
    "print(\"ðŸ” Validation set re-evaluation...\")\n",
    "val_preds_new, val_labels_new = get_model_predictions(val_dataset)\n",
    "val_acc_new = accuracy_score(val_labels_new, val_preds_new)\n",
    "\n",
    "# Re-evaluate on training set\n",
    "print(\"ðŸ” Training set re-evaluation...\")\n",
    "train_preds_new, train_labels_new = get_model_predictions(train_dataset)\n",
    "train_acc_new = accuracy_score(train_labels_new, train_preds_new)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FRESH EVALUATION RESULTS:\")\n",
    "print(f\"Training Accuracy:   {train_acc_new:.4f} ({train_acc_new*100:.2f}%)\")\n",
    "print(f\"Validation Accuracy: {val_acc_new:.4f} ({val_acc_new*100:.2f}%)\")\n",
    "print(f\"Accuracy Gap:        {train_acc_new - val_acc_new:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š COMPARISON WITH PREVIOUS RESULTS:\")\n",
    "print(f\"Previous training:   {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Previous validation: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"New training:        {train_acc_new:.4f} ({train_acc_new*100:.2f}%)\")\n",
    "print(f\"New validation:      {val_acc_new:.4f} ({val_acc_new*100:.2f}%)\")\n",
    "\n",
    "# Check consistency\n",
    "if abs(val_acc_new - accuracy) < 0.001 and abs(train_acc_new - train_accuracy) < 0.001:\n",
    "    print(f\"\\nâœ… RESULTS CONSISTENT: Your original evaluation was correct!\")\n",
    "    print(f\"   The 98.62% validation accuracy is legitimate.\")\n",
    "else:\n",
    "    print(f\"\\nâ“ INCONSISTENCY DETECTED: Results don't match - investigate further\")\n",
    "\n",
    "# Final verdict\n",
    "print(f\"\\nðŸ FINAL VERDICT:\")\n",
    "if val_acc_new > 0.98:\n",
    "    print(f\"âœ… Your model genuinely achieves {val_acc_new*100:.2f}% validation accuracy\")\n",
    "    print(f\"   This is exceptionally high but appears to be legitimate\")\n",
    "    print(f\"   Your fake news dataset may be particularly well-separated\")\n",
    "else:\n",
    "    print(f\"ðŸ“Š More reasonable validation accuracy: {val_acc_new*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89293ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” TEST SET PREDICTION ANALYSIS\n",
      "==================================================\n",
      "ðŸ“Š Prediction Confidence Analysis:\n",
      "Mean confidence: 0.9973\n",
      "Median confidence: 0.9998\n",
      "High confidence (>0.9): 9925/9983 (99.4%)\n",
      "Low confidence (<0.7): 15/9983 (0.2%)\n",
      "\n",
      "ðŸ“ˆ Predicted Class Distribution:\n",
      "Predicted Fake (0): 5028 (50.4%)\n",
      "Predicted Real (1): 4955 (49.6%)\n",
      "\n",
      "ðŸ”„ Distribution Comparison:\n",
      "Training - Fake: 51.4%, Real: 48.6%\n",
      "Test predictions - Fake: 50.4%, Real: 49.6%\n",
      "âœ… Similar distributions - accuracy should be close to validation\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” TEST SET PREDICTION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# You have these test variables:\n",
    "# test_pred_labels: ndarray (9983) - your predictions\n",
    "# test_labels: list (9983) - if you have true labels somehow\n",
    "# test_pred_probs: ndarray (9983) - prediction probabilities\n",
    "\n",
    "# Check confidence distribution\n",
    "confidence = np.max(test_pred_probs, axis=1)\n",
    "print(f\"ðŸ“Š Prediction Confidence Analysis:\")\n",
    "print(f\"Mean confidence: {confidence.mean():.4f}\")\n",
    "print(f\"Median confidence: {np.median(confidence):.4f}\")\n",
    "print(f\"High confidence (>0.9): {(confidence > 0.9).sum()}/{len(confidence)} ({(confidence > 0.9).mean()*100:.1f}%)\")\n",
    "print(f\"Low confidence (<0.7): {(confidence < 0.7).sum()}/{len(confidence)} ({(confidence < 0.7).mean()*100:.1f}%)\")\n",
    "\n",
    "# Class distribution in predictions\n",
    "pred_distribution = np.bincount(test_pred_labels)\n",
    "print(f\"\\nðŸ“ˆ Predicted Class Distribution:\")\n",
    "print(f\"Predicted Fake (0): {pred_distribution[0]} ({pred_distribution[0]/len(test_pred_labels)*100:.1f}%)\")\n",
    "print(f\"Predicted Real (1): {pred_distribution[1]} ({pred_distribution[1]/len(test_pred_labels)*100:.1f}%)\")\n",
    "\n",
    "# Compare with training distribution\n",
    "train_dist = np.bincount(train_labels)\n",
    "print(f\"\\nðŸ”„ Distribution Comparison:\")\n",
    "print(f\"Training - Fake: {train_dist[0]/len(train_labels)*100:.1f}%, Real: {train_dist[1]/len(train_labels)*100:.1f}%\")\n",
    "print(f\"Test predictions - Fake: {pred_distribution[0]/len(test_pred_labels)*100:.1f}%, Real: {pred_distribution[1]/len(test_pred_labels)*100:.1f}%\")\n",
    "\n",
    "# If distributions are very different, accuracy might be different\n",
    "dist_diff = abs((pred_distribution[0]/len(test_pred_labels)) - (train_dist[0]/len(train_labels)))\n",
    "if dist_diff > 0.1:\n",
    "    print(\"âš ï¸  Large distribution shift detected - accuracy may be different\")\n",
    "else:\n",
    "    print(\"âœ… Similar distributions - accuracy should be close to validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
